---
title: "Cytoreason Single-cell Analysis Pipeline"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(echo = FALSE)
library(plyr)
library(cytoreason)

devtools::load_all("~/capsule/code/service-single-cell")
devtools::load_all("~/capsule/code/cytoreason.cc.client/")
```

# Overview

* Requirements:
  - a workflow ID from an export single-cell dataset, as output by `sc_api_save_data()`
  - a configuration list that describes the dataset and the analysis models to fit
  - a supported disease model short key, i.e. available in `get_disease_model_metadata()`
  
* The pipeline proceeds as follows:
  - 

# Configuration
```{r config}
config <- sc_api_configuration(
  # asset_id [mandatory]: workflow ID of an exported single-cell dataset as 
  # output by `sc_api_save_data()`
  asset_id = "wf-371c007bc7",
  #asset_id = 'wf-a8e301eaec',
  cell_annotation = "biologist_annotation", # or: "final_2023"
  # experiment_id [optional]: experiment identifier.
  # If not provided, the default is to use the asset_id.
  # It does not need to be a GSE ID. 
  # Sample annotations are looked up in the Currator using this key, but the 
  # pipeline will not fail if it does not find any
  experiment_id = "GSE214695",
  
  # platform_id [optional]: platform ID, if not provided it will be "sc-rnaseq" 
  # Note however that the platform ID in the text files used by the platform API will  
  # always be set to "sc-rnaseq".
  platform_id = "GPL18573",
  
  # biosample_id [optional]: a string that indicates the name of the cell annotation
  # variable (in the cell metadata), which holds the bio-sample identifier, 
  # i.e. the key that is used to aggregate the single-cell data into a 
  # pseudobulk data
  biosample_id = "sample",
  # biosample_id = "donor_id",
  sample_annotations = read_data("~/capsule/code/UC/garrido-trigo_annotations_from_curator_cdc.csv",na.strings=''),
  # sample_annotations [optional]:
  # sample_annotations = list(
  #   # condition: values must be from the DOID ontology used in the Curator.
  #   # Here we can remap invalid values in the original data into valid ontology terms.
  #   # Values that are not remapped remain untouched.
  #   # Format: list(<original_variable_name> = c(new_value1 = old_value1, new_value2 = old_value2))
  #   condition = list(
  #     condition = c(control = "healthy",
  #                 "Crohn's disease" = "Crohn's disease")
  #   ),
  #   # tissue: values must be from the BTO ontology used in the Curator.
  #   # Here we can remap invalid values in the original data into valid ontology terms 
  #   # See example on 'condition' for format description
  #   tissue = list(
  #     tissue = c(
  #       # "colon" = "Normal ascending colon",
  #        "colon" = "colon sigmoideum",
  #        "colon" = "colon ascendens",
  #        "colon" = "colon descendens"
  #     )
  #   ),
  #   # 
  #   sample_classification = list(
  #     sample_classification = c("Inflamed" = "Inflamed", 
  #              Normal = "Normal")
  #   ),
  #   # directly use column `donor_id` as `subject_id`
  #   subject_id = "subject_id"
  #   # # a custom variable as a cross-product of 2 other variables
  #   # custom_variable = list(
  #   #   type = c("NonI", "Infl", "Heal"),
  #   #   disease = c(healthy = "normal",
  #   #               "CD" = "Crohn disease")
  #   # )
  # ),
  term_metadata = list(

     INF_VS_HC = list(
       # will only export this contrast term within this comparison
       INF_vs_HC = list(contrast_type = "inflamed_vs_healthy")
     )
  ),
  analysis_model = list(
        INF_VS_HC = list(
        # group variable: use `sample_classification`, while filtering
        # and enforcing level order
        group = list(
          sample_classification = c(HC = "Normal", INF = "Inflamed")
        )#,
        # pairing= "donor_id",
         #covariates = c("assay","layer")
        #covariates = "layer"
      )
  ),
  parameters = list(
    model=list(
      services = c("gx_diff", "ct_test"),
      gx_diff=list(min_sample_size=15),
      ct_test=list()
    )
  )
)



```


```{r}
# check the configuration locally
sc_validate_dataset_configuration(config)
# check that a valid dataset can be loaded from the config
pb_object <- prepare_single_cell_dataset(config)
# check a particular analysis model (if failing)
obj <- prepare_single_cell_dataset(config, validate = FALSE)
str(build_analysis_model_metadata(config$analysis_model$INF_VS_HC, obj))
```

## Available model keys
```{r model_keys, echo = FALSE}
knitr::kable(ldply(get_disease_model_metadata(), .id = "model_key", as.data.frame))
```

# Running the pipeline
```{r}
# launch piepline
sc_api_run_analysis("CD-CO", config, tags = list(message = "Garrido-Trige (GSE214695) CDc fix contrast name", tissue="colon", analysis="ct test and CSDE"))
# [Wed Mar 13 09:44:52 2024] run_analysis - wf-ddc0f07226
# [Sun Mar 17 09:04:56 2024] run_analysis - wf-e2048e016b - fix comparison 
# [Thu Mar 21 08:14:23 2024] run_analysis - wf-8cebeed32f - fix contrast name
# [Mon Mar 25 09:22:31 2024] run_analysis - wf-173f3f7fef - reran same as wf-8cebeed32f to see if it fixes the group b label
# [Mon Mar 25 10:21:11 2024] run_analysis - wf-1d85286457 - downloaded curator annotations locally
```

```{r}
model_md <- get_disease_model_metadata("CD-CO")
```

```{r}
model_key = "CD-CO"
test_run <- .worker__sc_analysis_pipeline(model_key, config)
```

# BQ upload ----
```{r}
make_upload_task <- function(wf_id, dataset_name, image, ..., 
                             memory_request = "500Mi",
                             task_name = "bq-upload",
                             data_access = get_workflow(wf_id)[["data_access"]]){
  if( !test_string(dataset_name, pattern = "^p[0-9xy]+_") ){
    message("* using BQ dataset: ... ", appendLF = FALSE)
    dataset_name <- .make_bq_dataset_name(dataset_name, data_access)
    message(dataset_name)
    
  }
  assert_string(dataset_name, pattern = "^p[0-9xy]+_")
  assert_string(wf_id)
  
  make_task(
    sprintf("python /app/cytobigquery/exec_service.py single_cell %s %s --verbose -sc -ti=%s -tm=124Mi",
            # NOTE: the uploader service is working on the old assumption of 2 workflow IDs
            wf_id,
            dataset_name,
            image),
    # CC config
    inputs = list(),
    outdir = "output/",
    image = image,
    memory_request = memory_request,
    task_name = task_name,
    ...
  )
  
}

combine_ds <- sc_api_save_analysis(c('wf-ddc0f07226'), dataset_name = "p00_cd_colon")
# wf-75a05a3472
```

#try to upload failed uploads
``` {r}
library(cytoreason.cc.client)

#########
# image #
#########
task_image = 'eu.gcr.io/cytoreason/cd-py-bigquery:develop_latest'
memory_request = '124Mi'

#####################
# ARGS (positional) #
#####################
service = 'single_cell'
dataset = 'p00_cd_colon'
text_wf_id = 'wf-8839a8f065'


###################
# ARGS (optional) #
###################
verbose = '--verbose' 
ti = sprintf('-ti=%s', task_image) 
tm = sprintf('-tm=%s', memory_request)


###########
# command #
###########
command <- sprintf('python /app/cytobigquery/exec_service.py %s %s %s %s %s %s', 
                   service, text_wf_id, dataset, verbose, ti, tm)

############
# workflow #
############
tags=list(list(name="de-process", value='bigquery-upload'),
          list(name="service", value=service),
          list(name="export_workflow", value=text_wf_id),
          list(name="target_dataset", value=dataset) 
          )
task_env_vars = list(list("name"="DE_PROCESS","value"="BigQuery_upload") 
                     )
wf <- run_command_dist(command, 
                       outdir = "./output/", 
                       image = task_image , 
                       task_env_vars = task_env_vars,
                       tags=tags,
                       memory_request = memory_request,
                       replace_image_tags = TRUE)

# wf-17ffac590e
```

#download curator annotations locally
```{r}
library(cytoreason.curator.annotations)
curator_annotations <- cytoreason.curator.annotations::get_annotations('GSE214695')
cdc_curator_annotations <- subset(curator_annotations, condition %in% c("healthy","Crohn's disease"))
write.csv(cdc_curator_annotations, 'garrido-trigo_annotations_from_curator_cdc.csv')
```
