---
title: "Cytoreason Single-cell Analysis Pipeline"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(echo = FALSE)
library(plyr)
library(cytoreason)

devtools::load_all("~/capsule/code/service-single-cell")
devtools::load_all("~/capsule/code/cytoreason.cc.client/")
```

# Overview

* Requirements:
  - a workflow ID from an export single-cell dataset, as output by `sc_api_save_data()`
  - a configuration list that describes the dataset and the analysis models to fit
  - a supported disease model short key, i.e. available in `get_disease_model_metadata()`
  
* The pipeline proceeds as follows:
  - 

# Configuration
```{r config}
config <- sc_api_configuration(
  # asset_id [mandatory]: workflow ID of an exported single-cell dataset as 
  # output by `sc_api_save_data()`
  asset_id = "wf-6ae43a9f66",
  #asset_id = 'wf-a8e301eaec',
  cell_annotation = "biologist_annotation", # or: "final_2023"
  # experiment_id [optional]: experiment identifier.
  # If not provided, the default is to use the asset_id.
  # It does not need to be a GSE ID. 
  # Sample annotations are looked up in the Currator using this key, but the 
  # pipeline will not fail if it does not find any
  experiment_id = "GSE214695",
  
  # platform_id [optional]: platform ID, if not provided it will be "sc-rnaseq" 
  # Note however that the platform ID in the text files used by the platform API will  
  # always be set to "sc-rnaseq".
  platform_id = "GPL18573",
  
  # biosample_id [optional]: a string that indicates the name of the cell annotation
  # variable (in the cell metadata), which holds the bio-sample identifier, 
  # i.e. the key that is used to aggregate the single-cell data into a 
  # pseudobulk data
  biosample_id = "sample",
  # biosample_id = "donor_id",
  
  # sample_annotations [optional]:
  sample_annotations = list(
    # condition: values must be from the DOID ontology used in the Curator.
    # Here we can remap invalid values in the original data into valid ontology terms.
    # Values that are not remapped remain untouched.
    # Format: list(<original_variable_name> = c(new_value1 = old_value1, new_value2 = old_value2))
    condition = list(
      condition = c(control = "healthy",
                  "ulcerative colitis" = "ulcerative colitis")
    ),
    # tissue: values must be from the BTO ontology used in the Curator.
    # Here we can remap invalid values in the original data into valid ontology terms 
    # See example on 'condition' for format description
    tissue = list(
      tissue = c(
        # "colon" = "Normal ascending colon",
         "colon" = "colon sigmoideum",
         "colon" = "rectum",
         "colon" = "colon transversum"
      )
    ),
    # 
    sample_classification = list(
      sample_classification = c("Inflamed" = "Inflamed", 
               Normal = "Normal")
    ),
    # directly use column `donor_id` as `subject_id`
    subject_id = "subject_id"
    # # a custom variable as a cross-product of 2 other variables
    # custom_variable = list(
    #   type = c("NonI", "Infl", "Heal"),
    #   disease = c(healthy = "normal",
    #               "CD" = "Crohn disease")
    # )
  ),
  term_metadata = list(

     UC_inf = list(
       # will only export this contrast term within this comparison
       DZ_inf_vs_HC = list(contrast_type = "inflamed_vs_healthy")
     )
  ),
  analysis_model = list(
        UC_inf = list(
        # group variable: use `sample_classification`, while filtering
        # and enforcing level order
        group = list(
          sample_classification = c(HC = "Normal", DZ_inf = "Inflamed")
        )#,
        # pairing= "donor_id",
         #covariates = c("assay","layer")
        #covariates = "layer"
      )
  ),
  parameters = list(
    model=list(
      services = c("gx_diff", "ct_test"),
      gx_diff=list(min_sample_size=15),
      ct_test=list()
    )
  )
)



```


```{r}
# check the configuration locally
sc_validate_dataset_configuration(config)
# check that a valid dataset can be loaded from the config
pb_object <- prepare_single_cell_dataset(config)
# check a particular analysis model (if failing)
obj <- prepare_single_cell_dataset(config, validate = FALSE)
str(build_analysis_model_metadata(config$analysis_model$UC_inf, obj))
```

## Available model keys
```{r model_keys, echo = FALSE}
knitr::kable(ldply(get_disease_model_metadata(), .id = "model_key", as.data.frame))
```

# Running the pipeline
```{r}
# launch piepline
sc_api_run_analysis("UC-CO", config, tags = list(message = "Garrido-Trige (GSE214695)", tissue="colon", analysis="ct test and CSDE"))
# [Tue Mar 12 13:22:03 2024] run_analysis - wf-3cb167f2a0
```

```{r}
model_md <- get_disease_model_metadata("UC-CO")
```

```{r}
model_key = "UC-CO"
test_run <- .worker__sc_analysis_pipeline(model_key, config)
```

# BQ upload ----
```{r}
make_upload_task <- function(wf_id, dataset_name, image, ..., 
                             memory_request = "500Mi",
                             task_name = "bq-upload",
                             data_access = get_workflow(wf_id)[["data_access"]]){
  if( !test_string(dataset_name, pattern = "^p[0-9xy]+_") ){
    message("* using BQ dataset: ... ", appendLF = FALSE)
    dataset_name <- .make_bq_dataset_name(dataset_name, data_access)
    message(dataset_name)
    
  }
  assert_string(dataset_name, pattern = "^p[0-9xy]+_")
  assert_string(wf_id)
  
  make_task(
    sprintf("python /app/cytobigquery/exec_service.py single_cell %s %s --verbose -sc -ti=%s -tm=124Mi",
            # NOTE: the uploader service is working on the old assumption of 2 workflow IDs
            wf_id,
            dataset_name,
            image),
    # CC config
    inputs = list(),
    outdir = "output/",
    image = image,
    memory_request = memory_request,
    task_name = task_name,
    ...
  )
  
}

combine_ds <- sc_api_save_analysis(c('wf-aaeda51e5f','wf-7445c55bf9','wf-3cb167f2a0'), dataset_name = "p00_ulcerative_colitis")#wf-aaeda51e5f
# wf-20a799040f
# wf-14e769ea7b with new smillie
# wf-510c75746d - newest smillie
# wf-f3d111d111 - newest smillie correct groups names
# wf-23042df180 - newest smilliet correct group names and cell names - V22
```

#try to upload failed uploads
``` {r}
library(cytoreason.cc.client)

#########
# image #
#########
task_image = 'eu.gcr.io/cytoreason/cd-py-bigquery:develop_latest'
memory_request = '124Mi'

#####################
# ARGS (positional) #
#####################
service = 'single_cell'
dataset = 'p00_ulcerative_colitis'
text_wf_id = 'wf-510c75746d'


###################
# ARGS (optional) #
###################
verbose = '--verbose' 
ti = sprintf('-ti=%s', task_image) 
tm = sprintf('-tm=%s', memory_request)


###########
# command #
###########
command <- sprintf('python /app/cytobigquery/exec_service.py %s %s %s %s %s %s', 
                   service, text_wf_id, dataset, verbose, ti, tm)

############
# workflow #
############
tags=list(list(name="de-process", value='bigquery-upload'),
          list(name="service", value=service),
          list(name="export_workflow", value=text_wf_id),
          list(name="target_dataset", value=dataset) 
          )
task_env_vars = list(list("name"="DE_PROCESS","value"="BigQuery_upload") 
                     )
wf <- run_command_dist(command, 
                       outdir = "./output/", 
                       image = task_image , 
                       task_env_vars = task_env_vars,
                       tags=tags,
                       memory_request = memory_request,
                       replace_image_tags = TRUE)

# wf-d0738e8908
```